{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d34f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f3121e-b0e4-46b0-ab2a-09540cec3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b280ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def EXIT_NOTEBOOK(): os._exit(00)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ba82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as func\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker\n",
    "\n",
    "# # ps\n",
    "# import pysindy as ps\n",
    "\n",
    "# sns.set_theme()\n",
    "# torch.set_default_dtype(torch.float32)\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a3b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 6\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f339b9d",
   "metadata": {},
   "source": [
    "# Dataset for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818019ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 546)\n",
      "[[ 7.05194125e-03  1.75234196e-02 -5.81392163e-02 ...  1.24990162e-01\n",
      "   1.56350070e-01  9.43220583e-02]\n",
      " [-3.75950043e-05  1.31899664e-02 -6.45355316e-02 ...  1.37983147e-01\n",
      "   1.49400399e-01  6.20559957e-02]\n",
      " [-3.12646260e-03 -1.73295189e-03 -7.47765357e-02 ...  1.25296032e-01\n",
      "   1.20838042e-01  4.32353530e-02]\n",
      " ...\n",
      " [ 5.28031238e-02 -5.41237270e-02 -8.76327714e-02 ...  1.37984240e-01\n",
      "   1.39722381e-01  2.38907456e-02]\n",
      " [ 1.73236259e-02 -3.70284150e-02 -1.03942641e-01 ...  1.41751850e-01\n",
      "   1.19050051e-01  3.47168143e-02]\n",
      " [ 8.86859586e-03 -3.74662119e-02 -1.06916334e-01 ...  1.49243320e-01\n",
      "   1.08279737e-01  3.47168143e-02]]\n"
     ]
    }
   ],
   "source": [
    "from BeadModel import Simulate\n",
    "from SimulationParameters import *\n",
    "\n",
    "X = Simulation(*Simulate(numSims)).positions[:,:,:,0].reshape(-1,11).T\n",
    "# Z = X.view\n",
    "\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cbd757",
   "metadata": {},
   "source": [
    "# Set the NN model and Solver with training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "606412e9",
   "metadata": {
    "code_folding": [
     2,
     18,
     19,
     28,
     42,
     45
    ]
   },
   "outputs": [],
   "source": [
    "def relu2(X): return func.relu(X)**2\n",
    "def tanh(X): return func.tanh(X)\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self,input_dim=6,output_dim=6,num_hidden=2,hidden_dim=10,act=func.tanh,transform=None):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.layers  = nn.ModuleList([nn.Linear(input_dim,hidden_dim)])\n",
    "        for _ in range(num_hidden-1): self.layers.append(nn.Linear(hidden_dim,hidden_dim))\n",
    "        self.act     = act\n",
    "        self.out     = nn.Linear(hidden_dim,output_dim)\n",
    "        self.transform = transform\n",
    "    def forward(self,X):\n",
    "        if self.transform is not None: X = self.transform(X)\n",
    "        for layer in self.layers: X = self.act(layer(X))\n",
    "        Y = self.out(X)\n",
    "        return Y\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,dim,model_U,unit_len=int(5e3)):\n",
    "        super().__init__()\n",
    "        self.dim      = dim\n",
    "        self.model_U  = model_U\n",
    "        self.unit_len = unit_len\n",
    "        self.mu       = nn.Parameter(torch.tensor([0.]*dim),requires_grad=False) \n",
    "        self.sigma    = nn.Parameter(torch.tensor([1.]*dim),requires_grad=False)\n",
    "        #above two lines should work, but if something doesn't work, check here! Does current self.mu and self.sigma code work if dim>1. Should return a vector since what we're trying to do is calculate mu\n",
    "        #and sigma separately for each imnputted feature. mu is parameter[0] for each row.\n",
    "        self.coef_U   = nn.Parameter(torch.tensor([1.]*dim),requires_grad=False)\n",
    "        #self.mu       = nn.Parameter(torch.tensor([0.]*dim).cuda(),requires_grad=False)\n",
    "        #self.sigma    = nn.Parameter(torch.tensor([1.]*dim).cuda(),requires_grad=False)\n",
    "        #self.coef_U   = nn.Parameter(torch.tensor(1.).cuda(),requires_grad=False)\n",
    "    def get_U_harmonic(self,X): return torch.sum(X**2,axis=-1)\n",
    "        \n",
    "    \n",
    "    def get_U_dU(self,X):\n",
    "        # normalize and ensure x is a tensor\n",
    "        if not torch.is_tensor(X): X = torch.tensor(X, requires_grad=True)\n",
    "        U = self.model_U(X).view(-1)\n",
    "        dU = torch.autograd.grad(U, X, torch.ones_like(U), create_graph=True)[0]\n",
    "        # dU = dU.T\n",
    "        return U,dU\n",
    "\n",
    "    \n",
    "    def get_U_np(self,X): \n",
    "        U,_ = self.get_U_dU(X);\n",
    "        return U.cpu().data.numpy()\n",
    "    \n",
    "    # def get_U_numerical_integration(self,X, dX):\n",
    "    #     outputU = []\n",
    "    #     _,dU = self.get_U_dU(X)\n",
    "    #     # Assume dU has more than two features. for each timestep we'll numerically integrate. current shape is 6x10\n",
    "    #     #Trapezoid rule for numerical integration by each timestep\n",
    "    #     for t in range(dU.shape[1]):\n",
    "    #         currentSum = 0\n",
    "    #         currentDU = dU[:,t]\n",
    "    #         for i in range(len(currentDU)):\n",
    "    #             if i == len(currentDU)-1 or i == 0:\n",
    "    #                 currentSum += currentDU[i] / 2\n",
    "    #             else:\n",
    "    #                 currentSum += currentDU[i]\n",
    "    #         currentSum *= dX\n",
    "    #         outputU.append(currentSum + sum(outputU))\n",
    "    #     U = torch.tensor(outputU)\n",
    "    #     return U\n",
    "\n",
    "    def get_U_numerical_integration(self,X, dX):\n",
    "        U = []\n",
    "        _,dU = self.get_U_dU(X)\n",
    "        # Assume dU has more than two features. for each timestep we'll numerically integrate. current shape is 6x10\n",
    "        #Trapezoid rule for numerical integration by each timestep\n",
    "        for t in range(dU.shape[1]):\n",
    "            currentPartialSumofU = 0\n",
    "            currentDU = dU[:,t]\n",
    "            for i in range(len(currentDU)):\n",
    "                if i == len(currentDU)-1 or i == 0:\n",
    "                    currentPartialSumofU += currentDU[i] / 2\n",
    "                else:\n",
    "                    currentPartialSumofU += currentDU[i]\n",
    "            currentU = currentPartialSumofU * dX\n",
    "            U.append(currentU)\n",
    "            \n",
    "        U = torch.tensor(U).T\n",
    "        return U\n",
    "\n",
    "    \n",
    "class Solver():\n",
    "    def __init__(self,model):\n",
    "        self.model=model\n",
    "    def train_model(self,data_train,data_test,get_loss,optimizer,\n",
    "                    n_steps,batch_size,scheduler=None,n_show_loss=100,error_model=None,use_tqdm=True):\n",
    "        if use_tqdm: step_range = tqdm(range(n_steps))\n",
    "        else: step_range = range(n_steps)\n",
    "        loss_step = []\n",
    "        for i_step in step_range:\n",
    "            if i_step%n_show_loss==0:\n",
    "                loss_train,loss_test = get_loss(self.model,data_train)[:-1],\\\n",
    "                                       get_loss(self.model,data_test)[:-1]\n",
    "                \n",
    "                def show_num(x): \n",
    "                    if abs(x)<100 and abs(x)>.01: return '%0.5f'%x\n",
    "                    else: return '%0.2e'%x\n",
    "                item1 = '%2dk'%np.int_(i_step/1000)\n",
    "                item2 = 'Loss: '+' '.join([show_num(k) for k in loss_train])\n",
    "                item3 = ' '.join([show_num(k) for k in loss_test])\n",
    "                item4 = ''\n",
    "                if error_model is not None: item4 = 'E(QP): %0.4f' % (error_model(self.model))\n",
    "                print(', '.join([item1,item2,item3,item4]))\n",
    "                loss_step = loss_step + [i_step] + [k.cpu().data.numpy() for k in loss_train]\\\n",
    "                                                 + [k.cpu().data.numpy() for k in loss_train]\n",
    "            data_batch = data_train[random.sample(range(len(data_train)),\n",
    "                                                  min(batch_size,len(data_train)))]\n",
    "#             print(i_step,data_batch.shape)\n",
    "            loss = get_loss(self.model,data_batch)[-1]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None: scheduler.step()\n",
    "        if error_model is not None: \n",
    "            print(\"Error: %0.5f\" % (error_model(self.model)))\n",
    "        return loss_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5786a635",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model_U = FCNN(input_dim=dim,output_dim=1,num_hidden=3,hidden_dim=10,act=tanh)#.cuda()\n",
    "model   = Model(dim,model_U=model_U)#.cuda();\n",
    "SOL     = Solver(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4f4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.get_U_dU(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e8e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.mu.shape)\n",
    "# print(model.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df5a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_model(model,cmap='terrain',max_V = 10):\n",
    "    \n",
    "#     xx     = np.linspace(0,2,1000).reshape(-1,1)\n",
    "#     U_NN   = model.get_U_np(xx)\n",
    "#     U_NN_min = U_NN.min()\n",
    "#     U_NN  = U_NN-U_NN_min\n",
    "\n",
    "#     fig, ax    = plt.subplots(1,1,figsize=(5,3),dpi=200,constrained_layout=True)\n",
    "#     c      = ax.plot(xx[:,0],U_NN,'-',lw=1.5,)\n",
    "\n",
    "#     ax.tick_params(axis=\"both\", labelsize=10)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82dfe6",
   "metadata": {},
   "source": [
    "# Set the loss function and Train the model for differen a_k(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69c4eeaf",
   "metadata": {
    "code_folding": [
     0,
     12,
     16
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.6870e-17, -8.6981e-06, -1.1297e-05, -2.0260e-05, -3.1139e-05,\n",
      "        -5.3784e-05, -5.1633e-05, -6.8734e-05, -2.7100e-05, -1.6480e-17])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (11x546 and 6x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;66;03m#,loss\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# plot_model(model)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 27\u001b[0m, in \u001b[0;36mget_loss\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     25\u001b[0m X \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     26\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m _,dU \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_U_dU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m getAllResidues(X, dU)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[0;32mIn[7], line 38\u001b[0m, in \u001b[0;36mModel.get_U_dU\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_U_dU\u001b[39m(\u001b[38;5;28mself\u001b[39m,X):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# normalize and ensure x is a tensor\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(X): X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 38\u001b[0m     U \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_U\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m     dU \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(U, X, torch\u001b[38;5;241m.\u001b[39mones_like(U), create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# dU = dU.T\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mFCNN.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,X):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers: X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(X)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Y\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (11x546 and 6x10)"
     ]
    }
   ],
   "source": [
    "from Loss import getResidue, getAllResidues\n",
    "\n",
    "# def plot_model(model,cmap='terrain',max_V = 10):\n",
    "    \n",
    "#     # xx     = np.linspace(0,2,1000).reshape(-1,1)\n",
    "#     # U_NN   = model.get_U_np(xx)\n",
    "#     U_NN   = model.get_U_np(X)\n",
    "#     U_NN_min = U_NN.min()\n",
    "#     U_NN  = U_NN-U_NN_min\n",
    "#     fig, ax    = plt.subplots(1,1,figsize=(5,3),dpi=200,constrained_layout=True)\n",
    "#     c      = ax.plot(X[:,0],U_NN,'-',lw=1.5,)\n",
    "\n",
    "    # ax.tick_params(axis=\"both\", labelsize=10)\n",
    "    # plt.show()\n",
    "\n",
    "def plot_model(model,cmap='terrain',max_V = 10,):\n",
    "    xx     = np.linspace(0,2,1000).reshape(-1,1)\n",
    "    U_NN = model.get_U_numerical_integration(X, dX = 1/500)\n",
    "    U_NN_min = U_NN.min()\n",
    "    U_NN  = U_NN-U_NN_min\n",
    "    fig, ax    = plt.subplots(1,1,figsize=(5,3),dpi=200,constrained_layout=True)\n",
    "    c        = ax.plot(xx[:,0],U_NN,'-',lw=1.5)\n",
    "\n",
    "def get_loss(model,data):\n",
    "    X = data\n",
    "    X = torch.tensor(X).clone().detach().requires_grad_(True)\n",
    "    _,dU = model.get_U_dU(X)\n",
    "    loss = getAllResidues(X, dU)\n",
    "    return loss#,loss\n",
    "\n",
    "\n",
    "# plot_model(model)\n",
    "get_loss(model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65d4b29e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedb950a746546c893c52448b424e3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0k, Loss: -9.83e-03 -7.79e-03 -6.18e-03 -6.90e-03 -9.70e-03 -8.50e-03 -9.80e-03 -7.89e-03 -4.97e-03 -5.54e-03, -9.83e-03 -7.79e-03 -6.18e-03 -6.90e-03 -9.70e-03 -8.50e-03 -9.80e-03 -7.89e-03 -4.97e-03 -5.54e-03, \n",
      " 1k, Loss: -0.11641 -0.11615 -0.12700 -0.13520 -0.13807 -0.18763 -0.20134 -0.25390 -0.28543 -0.26060, -0.11641 -0.11615 -0.12700 -0.13520 -0.13807 -0.18763 -0.20134 -0.25390 -0.28543 -0.26060, \n",
      " 2k, Loss: -0.12446 -0.12378 -0.13494 -0.14583 -0.14541 -0.19164 -0.20417 -0.25242 -0.27844 -0.25575, -0.12446 -0.12378 -0.13494 -0.14583 -0.14541 -0.19164 -0.20417 -0.25242 -0.27844 -0.25575, \n",
      " 3k, Loss: -0.12521 -0.12518 -0.13704 -0.14897 -0.14664 -0.19223 -0.20489 -0.25361 -0.27965 -0.25704, -0.12521 -0.12518 -0.13704 -0.14897 -0.14664 -0.19223 -0.20489 -0.25361 -0.27965 -0.25704, \n",
      " 4k, Loss: -0.12401 -0.12546 -0.13859 -0.15123 -0.14674 -0.19195 -0.20472 -0.25397 -0.28163 -0.25944, -0.12401 -0.12546 -0.13859 -0.15123 -0.14674 -0.19195 -0.20472 -0.25397 -0.28163 -0.25944, \n",
      " 5k, Loss: -0.12195 -0.12571 -0.14043 -0.15421 -0.14713 -0.19126 -0.20314 -0.25316 -0.28677 -0.26006, -0.12195 -0.12571 -0.14043 -0.15421 -0.14713 -0.19126 -0.20314 -0.25316 -0.28677 -0.26006, \n",
      " 6k, Loss: -0.12486 -0.13155 -0.14881 -0.16614 -0.14741 -0.18980 -0.20080 -0.25314 -0.28916 -0.25737, -0.12486 -0.13155 -0.14881 -0.16614 -0.14741 -0.18980 -0.20080 -0.25314 -0.28916 -0.25737, \n",
      " 7k, Loss: -0.12441 -0.13102 -0.14839 -0.16539 -0.14825 -0.19206 -0.20455 -0.25540 -0.28948 -0.25906, -0.12441 -0.13102 -0.14839 -0.16539 -0.14825 -0.19206 -0.20455 -0.25540 -0.28948 -0.25906, \n",
      " 8k, Loss: -0.12526 -0.13165 -0.14834 -0.16559 -0.14773 -0.19022 -0.20203 -0.25427 -0.28933 -0.25573, -0.12526 -0.13165 -0.14834 -0.16559 -0.14773 -0.19022 -0.20203 -0.25427 -0.28933 -0.25573, \n",
      " 9k, Loss: -0.12463 -0.13116 -0.14870 -0.16545 -0.14787 -0.19173 -0.20413 -0.25381 -0.29108 -0.26071, -0.12463 -0.13116 -0.14870 -0.16545 -0.14787 -0.19173 -0.20413 -0.25381 -0.29108 -0.26071, \n",
      "10k, Loss: -0.12525 -0.13142 -0.14820 -0.16509 -0.14835 -0.19217 -0.20409 -0.25469 -0.29284 -0.25885, -0.12525 -0.13142 -0.14820 -0.16509 -0.14835 -0.19217 -0.20409 -0.25469 -0.29284 -0.25885, \n",
      "11k, Loss: -0.12521 -0.13123 -0.14830 -0.16471 -0.14823 -0.19217 -0.20435 -0.25188 -0.28980 -0.25979, -0.12521 -0.13123 -0.14830 -0.16471 -0.14823 -0.19217 -0.20435 -0.25188 -0.28980 -0.25979, \n",
      "12k, Loss: -0.12467 -0.13145 -0.14899 -0.16662 -0.14784 -0.19146 -0.20315 -0.25496 -0.29203 -0.25915, -0.12467 -0.13145 -0.14899 -0.16662 -0.14784 -0.19146 -0.20315 -0.25496 -0.29203 -0.25915, \n",
      "13k, Loss: -0.12529 -0.13124 -0.14796 -0.16455 -0.14816 -0.19208 -0.20427 -0.25374 -0.29240 -0.25972, -0.12529 -0.13124 -0.14796 -0.16455 -0.14816 -0.19208 -0.20427 -0.25374 -0.29240 -0.25972, \n",
      "14k, Loss: -0.12515 -0.13144 -0.14871 -0.16586 -0.14810 -0.19191 -0.20386 -0.25417 -0.29271 -0.25997, -0.12515 -0.13144 -0.14871 -0.16586 -0.14810 -0.19191 -0.20386 -0.25417 -0.29271 -0.25997, \n",
      "15k, Loss: -0.12528 -0.13105 -0.14753 -0.16371 -0.14813 -0.19206 -0.20441 -0.25021 -0.28953 -0.25814, -0.12528 -0.13105 -0.14753 -0.16371 -0.14813 -0.19206 -0.20441 -0.25021 -0.28953 -0.25814, \n",
      "16k, Loss: -0.12538 -0.13131 -0.14815 -0.16471 -0.14812 -0.19226 -0.20483 -0.25139 -0.28874 -0.25912, -0.12538 -0.13131 -0.14815 -0.16471 -0.14812 -0.19226 -0.20483 -0.25139 -0.28874 -0.25912, \n",
      "17k, Loss: -0.12501 -0.13125 -0.14869 -0.16552 -0.14811 -0.19224 -0.20448 -0.25345 -0.29144 -0.26008, -0.12501 -0.13125 -0.14869 -0.16552 -0.14811 -0.19224 -0.20448 -0.25345 -0.29144 -0.26008, \n",
      "18k, Loss: -0.12539 -0.13147 -0.14848 -0.16592 -0.14800 -0.19116 -0.20347 -0.25525 -0.29042 -0.25783, -0.12539 -0.13147 -0.14848 -0.16592 -0.14800 -0.19116 -0.20347 -0.25525 -0.29042 -0.25783, \n",
      "19k, Loss: -0.12567 -0.13198 -0.14904 -0.16725 -0.14630 -0.18637 -0.19672 -0.24943 -0.28458 -0.25192, -0.12567 -0.13198 -0.14904 -0.16725 -0.14630 -0.18637 -0.19672 -0.24943 -0.28458 -0.25192, \n",
      "20k, Loss: -0.12548 -0.13158 -0.14883 -0.16620 -0.14776 -0.19149 -0.20386 -0.25519 -0.29210 -0.25944, -0.12548 -0.13158 -0.14883 -0.16620 -0.14776 -0.19149 -0.20386 -0.25519 -0.29210 -0.25944, \n",
      "21k, Loss: -0.12540 -0.13151 -0.14848 -0.16592 -0.14848 -0.19252 -0.20474 -0.25560 -0.29204 -0.25813, -0.12540 -0.13151 -0.14848 -0.16592 -0.14848 -0.19252 -0.20474 -0.25560 -0.29204 -0.25813, \n",
      "22k, Loss: -0.12517 -0.13117 -0.14836 -0.16504 -0.14840 -0.19249 -0.20463 -0.25156 -0.29027 -0.25921, -0.12517 -0.13117 -0.14836 -0.16504 -0.14840 -0.19249 -0.20463 -0.25156 -0.29027 -0.25921, \n",
      "23k, Loss: -0.12515 -0.13099 -0.14794 -0.16441 -0.14857 -0.19261 -0.20497 -0.25248 -0.29044 -0.25937, -0.12515 -0.13099 -0.14794 -0.16441 -0.14857 -0.19261 -0.20497 -0.25248 -0.29044 -0.25937, \n",
      "24k, Loss: -0.12531 -0.13142 -0.14848 -0.16565 -0.14847 -0.19242 -0.20414 -0.25232 -0.29149 -0.25945, -0.12531 -0.13142 -0.14848 -0.16565 -0.14847 -0.19242 -0.20414 -0.25232 -0.29149 -0.25945, \n",
      "25k, Loss: -0.12543 -0.13145 -0.14840 -0.16583 -0.14804 -0.19113 -0.20338 -0.25502 -0.29046 -0.25849, -0.12543 -0.13145 -0.14840 -0.16583 -0.14804 -0.19113 -0.20338 -0.25502 -0.29046 -0.25849, \n",
      "26k, Loss: -0.12523 -0.13118 -0.14778 -0.16474 -0.14912 -0.19333 -0.20565 -0.25488 -0.29178 -0.25805, -0.12523 -0.13118 -0.14778 -0.16474 -0.14912 -0.19333 -0.20565 -0.25488 -0.29178 -0.25805, \n",
      "27k, Loss: -0.12548 -0.13160 -0.14922 -0.16664 -0.14710 -0.19053 -0.20255 -0.25322 -0.29231 -0.26103, -0.12548 -0.13160 -0.14922 -0.16664 -0.14710 -0.19053 -0.20255 -0.25322 -0.29231 -0.26103, \n",
      "28k, Loss: -0.12497 -0.13085 -0.14754 -0.16405 -0.14857 -0.19266 -0.20519 -0.25197 -0.29113 -0.25864, -0.12497 -0.13085 -0.14754 -0.16405 -0.14857 -0.19266 -0.20519 -0.25197 -0.29113 -0.25864, \n",
      "29k, Loss: -0.12545 -0.13150 -0.14824 -0.16559 -0.14867 -0.19278 -0.20527 -0.25601 -0.29140 -0.25782, -0.12545 -0.13150 -0.14824 -0.16559 -0.14867 -0.19278 -0.20527 -0.25601 -0.29140 -0.25782, \n",
      "30k, Loss: -0.12547 -0.13150 -0.14861 -0.16591 -0.14827 -0.19234 -0.20468 -0.25529 -0.29240 -0.25926, -0.12547 -0.13150 -0.14861 -0.16591 -0.14827 -0.19234 -0.20468 -0.25529 -0.29240 -0.25926, \n",
      "31k, Loss: -0.12545 -0.13149 -0.14841 -0.16574 -0.14860 -0.19282 -0.20523 -0.25555 -0.29153 -0.25854, -0.12545 -0.13149 -0.14841 -0.16574 -0.14860 -0.19282 -0.20523 -0.25555 -0.29153 -0.25854, \n",
      "32k, Loss: -0.12529 -0.13128 -0.14861 -0.16569 -0.14822 -0.19246 -0.20461 -0.25440 -0.29229 -0.25970, -0.12529 -0.13128 -0.14861 -0.16569 -0.14822 -0.19246 -0.20461 -0.25440 -0.29229 -0.25970, \n",
      "33k, Loss: -0.12515 -0.13122 -0.14837 -0.16556 -0.14778 -0.19157 -0.20363 -0.25338 -0.29318 -0.25972, -0.12515 -0.13122 -0.14837 -0.16556 -0.14778 -0.19157 -0.20363 -0.25338 -0.29318 -0.25972, \n",
      "34k, Loss: -0.12525 -0.13106 -0.14853 -0.16541 -0.14727 -0.19106 -0.20384 -0.25462 -0.29091 -0.26019, -0.12525 -0.13106 -0.14853 -0.16541 -0.14727 -0.19106 -0.20384 -0.25462 -0.29091 -0.26019, \n",
      "35k, Loss: -0.12469 -0.13072 -0.14839 -0.16613 -0.14549 -0.18793 -0.19919 -0.25246 -0.28752 -0.25663, -0.12469 -0.13072 -0.14839 -0.16613 -0.14549 -0.18793 -0.19919 -0.25246 -0.28752 -0.25663, \n",
      "36k, Loss: -0.12553 -0.13156 -0.14872 -0.16625 -0.14813 -0.19188 -0.20396 -0.25523 -0.29279 -0.25898, -0.12553 -0.13156 -0.14872 -0.16625 -0.14813 -0.19188 -0.20396 -0.25523 -0.29279 -0.25898, \n",
      "37k, Loss: -0.12524 -0.13102 -0.14809 -0.16447 -0.14877 -0.19321 -0.20628 -0.25349 -0.29084 -0.25950, -0.12524 -0.13102 -0.14809 -0.16447 -0.14877 -0.19321 -0.20628 -0.25349 -0.29084 -0.25950, \n",
      "38k, Loss: -0.12543 -0.13145 -0.14892 -0.16609 -0.14819 -0.19220 -0.20473 -0.25578 -0.29166 -0.26055, -0.12543 -0.13145 -0.14892 -0.16609 -0.14819 -0.19220 -0.20473 -0.25578 -0.29166 -0.26055, \n",
      "39k, Loss: -0.12546 -0.13148 -0.14905 -0.16613 -0.14871 -0.19260 -0.20491 -0.25591 -0.29120 -0.26078, -0.12546 -0.13148 -0.14905 -0.16613 -0.14871 -0.19260 -0.20491 -0.25591 -0.29120 -0.26078, \n",
      "40k, Loss: -0.12558 -0.13163 -0.14942 -0.16634 -0.14835 -0.19143 -0.20361 -0.25531 -0.29094 -0.26005, -0.12558 -0.13163 -0.14942 -0.16634 -0.14835 -0.19143 -0.20361 -0.25531 -0.29094 -0.26005, \n",
      "41k, Loss: -0.12544 -0.13152 -0.14925 -0.16627 -0.14972 -0.19363 -0.20612 -0.25564 -0.28966 -0.26134, -0.12544 -0.13152 -0.14925 -0.16627 -0.14972 -0.19363 -0.20612 -0.25564 -0.28966 -0.26134, \n",
      "42k, Loss: -0.12549 -0.13147 -0.14921 -0.16630 -0.15008 -0.19358 -0.20604 -0.25614 -0.29077 -0.26142, -0.12549 -0.13147 -0.14921 -0.16630 -0.15008 -0.19358 -0.20604 -0.25614 -0.29077 -0.26142, \n",
      "43k, Loss: -0.12564 -0.13162 -0.14946 -0.16646 -0.14986 -0.19337 -0.20606 -0.25640 -0.29014 -0.26145, -0.12564 -0.13162 -0.14946 -0.16646 -0.14986 -0.19337 -0.20606 -0.25640 -0.29014 -0.26145, \n",
      "44k, Loss: -0.12543 -0.13134 -0.14962 -0.16642 -0.14882 -0.19199 -0.20403 -0.25458 -0.29300 -0.26055, -0.12543 -0.13134 -0.14962 -0.16642 -0.14882 -0.19199 -0.20403 -0.25458 -0.29300 -0.26055, \n",
      "45k, Loss: -0.12505 -0.13118 -0.14890 -0.16633 -0.14983 -0.19252 -0.20462 -0.25606 -0.29032 -0.26080, -0.12505 -0.13118 -0.14890 -0.16633 -0.14983 -0.19252 -0.20462 -0.25606 -0.29032 -0.26080, \n",
      "46k, Loss: -0.12559 -0.13158 -0.14954 -0.16693 -0.15035 -0.19303 -0.20516 -0.25584 -0.28970 -0.26077, -0.12559 -0.13158 -0.14954 -0.16693 -0.15035 -0.19303 -0.20516 -0.25584 -0.28970 -0.26077, \n",
      "47k, Loss: -0.12569 -0.13165 -0.14982 -0.16682 -0.15003 -0.19341 -0.20557 -0.25541 -0.29205 -0.26154, -0.12569 -0.13165 -0.14982 -0.16682 -0.15003 -0.19341 -0.20557 -0.25541 -0.29205 -0.26154, \n",
      "48k, Loss: -0.12558 -0.13156 -0.14979 -0.16670 -0.15012 -0.19314 -0.20526 -0.25578 -0.29227 -0.26137, -0.12558 -0.13156 -0.14979 -0.16670 -0.15012 -0.19314 -0.20526 -0.25578 -0.29227 -0.26137, \n",
      "49k, Loss: -0.12556 -0.13156 -0.14976 -0.16653 -0.15054 -0.19390 -0.20608 -0.25532 -0.29156 -0.26161, -0.12556 -0.13156 -0.14976 -0.16653 -0.15054 -0.19390 -0.20608 -0.25532 -0.29156 -0.26161, \n",
      "50k, Loss: -0.12554 -0.13146 -0.14948 -0.16612 -0.15069 -0.19400 -0.20667 -0.25598 -0.29088 -0.26168, -0.12554 -0.13146 -0.14948 -0.16612 -0.15069 -0.19400 -0.20667 -0.25598 -0.29088 -0.26168, \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1000,) and torch.Size([6])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m _loss_step \u001b[38;5;241m=\u001b[39m SOL\u001b[38;5;241m.\u001b[39mtrain_model(data_train\u001b[38;5;241m=\u001b[39mX,data_test\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m     11\u001b[0m                              get_loss\u001b[38;5;241m=\u001b[39mget_loss,optimizer\u001b[38;5;241m=\u001b[39moptimizer,scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m     12\u001b[0m                              n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m5e4\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,n_show_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,use_tqdm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# torch.save(model.state_dict(), \"savee/model_\"+str(choose_id))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#torch.save(model.state_dict(),\"savee/model_anaconda3\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m, in \u001b[0;36mplot_model\u001b[0;34m(model, cmap, max_V)\u001b[0m\n\u001b[1;32m     20\u001b[0m U_NN  \u001b[38;5;241m=\u001b[39m U_NN\u001b[38;5;241m-\u001b[39mU_NN_min\n\u001b[1;32m     21\u001b[0m fig, ax    \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m3\u001b[39m),dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,constrained_layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 22\u001b[0m c        \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mU_NN\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1000,) and torch.Size([6])"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/8AAAJvCAYAAAAtE2GhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAB7CAAAewgFu0HU+AAAo/UlEQVR4nO3dT27baJ744W/9UIteKg4agwJiYJrZzGY2klOLXsympBtIyAli3cBCTlCQbyD6BIl0A8nbWXRsrmdjZmEDwaDRNpezaEC/RYHquGK7ZEf0n9fPAwRIm9QrpsJW9CFfkj8sl8tlAAAAAMn6fw+9AQAAAECzxD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDiGo//oiji9evXUVXVRsbL8zx6vV4Mh8MYDAYxGAyiKIqNjA0AAAAp+rGpgYuiiMlkEnmeb2zMwWAQZVnG4eFhtFqtiIgoyzI6nU6Mx+PY3d3d2HsBAABAKjZ+5n9/fz86nU5MJpMYDAarSP9eeZ7HbDa7FP4REVmWxcHBQQyHQzMAAAAA4Ao/LJfLZZNv8OLFi6iqKi4uLr7rQMCLFy9iZ2cn5vP5lct/+OGH6Ha71y4HAACA5+pJ3PCvKIqoqira7fa167Tb7VgsFhu7twAAAACk4knE/4cPHyIi4uXLl9eus7W1FRERi8XiXrYJAAAAnoonEf910N902UC97NOnT/ewRQAAAPB0NHa3/02qp/LXZ/evUi+7y7T/s7OzG5f/3//9X/zP//xP/Nu//Vv8+c9/jh9/fBL/2QAAALhH//znP+Pvf/97RET853/+Z/zpT3964C36lydRsefn542sW9ve3r71awAAAOA6f/vb3+LNmzcPvRkrT2LaPwAAAHB3T+LMf9NOT0//cPlf//rXiPjt6M1PP/10H5sFAADAE/Lly5f4+eefIyLiz3/+8wNvzWVPIv63traiqqq1pvTfdF+A67x69WrtdX/66adbrQ8AAMDz89juFfckpv3fdJf/Wn1gYJ11AQAA4Dl5EvG/s7MTEREnJyfXrlOWZUTEo7qhAgAAADwGTyL+e71eRNz8GL96Wb/fv4ctAgAAgKfjScR/HfSLxeLK5VVVRVmW0W6373OzAAAA4El4NPFflmV0Op0YDodXLh+Px1GW5Wp6/9c+fvwYEREHBweNbiMAAAA8RY3Gf1mWq+n4R0dHN647mUyiKIrI8zyKovhm+d7eXvT7/ej1epem/xdFEaPRKMbjsTP/AAAAcIWNP3tgNpvFr7/+uno0X333/cFgEFtbW9FqteLt27ext7d36XVv376N2WwWWZZdG/HT6TTyPI/BYBBZlsX5+XlUVRXT6TS63e6m/ygAAACQhB+Wy+XyoTfisTs7O4vt7e2IiDg9PY1Xr1498BYBAADw2Dzmdnw01/wDAAAAzRD/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkLgfmxw8z/OYTqeRZVmcn59HRMT79++j3W5/17iz2Sw+fPgQERFVVUVExHA4jH6//13jAgAAQIoai//BYBBlWcbh4WG0Wq2IiCjLMjqdTozH49jd3b3zuL1eL6bT6epnVVXFYDCIDx8+XPo5AAAA0NC0/zzPYzabXQr/iIgsy+Lg4CCGw2EURXHrcff39+PNmzffHDhotVoxn8+jKIrI8/x7Nx8AAACS0kj8j0aj6Ha7l8K/Vk/NH41Gtx53MpncOLV/OBw68w8AAAC/s/H4L4oiqqq68br+drsdi8Vidb3+usqyvHHGQKvVWt1bAAAAAPjNxuO/vhHfy5cvr11na2srIiIWi8Wtx3/37t21BwDm83l0u91bjwkAAAAp23j810F/1ZT/Wr3s06dPtxq73+9HVVXR6XS+uWxgsVjEYrGI9+/f32pMAAAASN3G7/ZfT+Wvz+5fpV5222n/BwcHq8sF9vf3YzabxWQyibIsYzKZxOfPn2886HCds7OzG5d/+fLl1mMCAADAY7Hx+L/NNfe3vT6/1WrF58+fYzAYxGKxiLIso9frRZZlcXx8fKfwj4jY3t6+0+sAAADgKWjkbv9NarVa0ev1Lt1QsCzL+Mtf/nKnewgAAABA6p5U/NfX+0dEHB8fx8XFxerRf1VVRa/Xi9lsdutxT09Pb/z1t7/9baN/DgAAALhPG5/2v7W1FVVVrTWl/6b7Alzll19+iW63G3t7exHx2yyA6XQai8UiBoNBVFUV7969Wx0QWNerV69utT4AAAA8JRs/87/Odff1gYHbXKOf53mUZRnj8fibZd1uNz5//hztdjuqqoo8z9ceFwAAAFK38fjf2dmJiIiTk5Nr1ynLMiIi3rx5s/a48/k8ut3utctbrVYcHh5GxG+XBAAAAAC/2Xj893q9iLj5MX71sttMzy/L8g8vE2i1WpFlWbx+/XrtcQEAACB1G4//Ouivu/N+VVVRluWlu/Wvo9vtrnU3/7Isb5whAAAAAM9NI3f7H4/HUZblanr/1z5+/BgREQcHB98sK8syOp1ODIfDb5YNh8Moy/LG6/nzPI9+v3/rAwsAAACQskbif29vL/r9fvR6vUvT/4uiiNFoFOPx+MpAn0wmURRF5HkeRVFcWpZlWczn8xiNRrG/v39pWVVVMRqNYjqdxnQ6beKPBAAAAE/Wxh/1V5tOp5HneQwGg8iyLM7Pz6OqqphOp9dOy3/79m3MZrPIsuzKgwP1Xf1//fXX6HQ6EfGvxwUOh8MrnwQAAAAAz90Py+Vy+dAb8didnZ3F9vZ2REScnp7Gq1evHniLAAAAeGweczs2Mu0fAAAAeDzEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACTuxyYHz/M8ptNpZFkW5+fnERHx/v37aLfb3z12WZYxHo/j6Ogotra2IiJiMBjE7u7ud48NAAAAKWks/geDQZRlGYeHh9FqtSLit2DvdDoxHo+/K9LzPI/RaBQHBwcxmUxWPx+NRpHnuQMAAAAA8JVG4j/P85jNZnFxcbEK/4iILMvi4OAgBoNB7Ozs3GkGQJ7nMRwOYz6fR7fbXf18sVhEnueRZZn4BwAAgK80cs3/aDSKbrd7Kfxr/X5/tc5tlWUZw+Ew+v3+pfCPiCiKIqqqiqqq7rLJAAAAkKyNn/mvI/yms/rtdjsWi0VUVXXlAYLrDIfDiPjtvgG/t7e3F61W65uDAgAAAPDcbfzM/4cPHyIi4uXLl9euU9+gb7FYrD1uWZar9a87sLC7uxtZlq09JgAAADwHG4//OtBvOqNfL/v06dPa485ms4j4V/iXZRmj0ShGo9GtDiIAAADAc7Pxaf/1Nff12f2r1Mtuc31+faBga2srFotFzOfzGA6HsbW1FXmex2AwiMPDwzvdRPDs7OzG5V++fLn1mAAAAPBYbDz+z8/PG1m3LMvV7+fzeYzH49X/3tvbi3/84x/R6XTi+Pj41gcAtre3b7U+AAAAPCWN3O2/CfUsgcVisbrx39fqn7179+4+NwsAAAAevY2f+W9KfZ+ALMuuvKlf/bOiKKIoilud/T89Pb1x+ZcvX+Lnn39ef2MBAADgEdl4/G9tbUVVVWtN6b/pvgDXrXvT3fxbrVZUVRVHR0e3iv9Xr16tvS4AAAA8NRuf9n/TXf5r9YGBddatrfMIv/oAwfHx8drjAgAAQOo2Hv87OzsREXFycnLtOvXN+968ebP2uJ1O5w/XqQ8qvH79eu1xAQAAIHUbj/9erxcRNz/Gr17W7/fXHrfb7UZExNHR0R+ue5fH/QEAAECqNh7/ddAvFosrl1dVFWVZ3jrQsyyLdrsdVVVdeWChLMuoqipardbqQAEAAADQ0KP+xuNxlGW5mt7/tY8fP0ZExMHBwTfLyrKMTqdz5aP86nG/HuNrs9ns2nEBAADgOWsk/vf29qLf70ev17t0lr4oihiNRjEej6888z+ZTKIoisjzPIqi+GZ5t9uN8Xgcw+Hw0syCxWIRo9Fo9b4AAADAv/ywXC6XTQ2e53lMp9PIsizOz8+jqqoYjUbXTssviiIGg0FkWRbz+fzacReLRYzH49UN/rIsi+Fw2Nh0/7Ozs9je3o6IiNPTU48GBAAA4BuPuR0bjf9UPOa/QAAAAB6Hx9yOjUz7BwAAAB4P8Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJE/8AAACQOPEPAAAAiRP/AAAAkDjxDwAAAIkT/wAAAJA48Q8AAACJazT+8zyPXq8Xw+EwBoNBDAaDKIqikffqdDqNjQ0AAABP2Y9NDTwYDKIsyzg8PIxWqxUREWVZRqfTifF4HLu7uxt7r9FoJPwBAADgGo3Ef57nMZvN4uLiYhX+ERFZlsXBwUEMBoPY2dmJdrv93e9VFEXs7+9/9zgAAACQqkam/Y9Go+h2u5fCv9bv91frbOq9NnEQAQAAAFK18fgviiKqqroxyNvtdiwWi6iq6rveazQaxWg0iq2tre8aBwAAAFK28fj/8OFDRES8fPny2nXqWF8sFnd+n7Iso6qq6Ha7dx4DAAAAnoONx38d9FdN+a/Vyz59+nTn9xkOhzGZTO78egAAAHguNn7Dv3oq/01T8etld532v7+/v7F7BkREnJ2d3bj8y5cvG3svAAAAuG8bj//z8/NG1q2VZRknJyext7d369deZ3t7e2NjAQAAwGPTyKP+mjQcDmM6nT70ZgAAAMCT8aTiv57uf9P9BO7i9PT0xuVfvnyJn3/+eaPvCQAAAPdl4/G/tbUVVVWtNaX/No/oa2K6f+3Vq1cbHxMAAAAei43H/zpn5esDA7c5g2+6PwAAANzNxuN/Z2cniqKIk5OTa9cpyzIiIt68ebPWmEVRxNHRUXQ6nRvH++WXX1azCW56fwAAAHhONh7/vV4v8jy/8TF+9bJ+v7/WmO12Oy4uLq5d/uLFi6iqKg4PD6Pdbt9mcwEAACB5/2/TA9ZBv1gsrlxeVVWUZSnSAQAA4J5sPP4jIsbjcZRluZqO/7WPHz9GRMTBwcE3y8qyjE6nE8Ph8E7vu85NBgEAAOC5aST+9/b2ot/vR6/XuzT9vyiKGI1GMR6PrzzzP5lMoiiKyPM8iqJY672qqlq9x1UHGwAAAOC5+2G5XC6bGjzP85hOp5FlWZyfn0dVVTEajaLb7V65flEUMRgMIsuymM/nN469v78fk8nk0tn+qqoiy7JotVpxfHy8sT/H2dlZbG9vR0TE6empRwMCAADwjcfcjo3Gfyoe818gAAAAj8NjbsdGpv0DAAAAj4f4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMQ1Gv95nkev14vhcBiDwSAGg0EURfHd4+7v70ev14sXL17E69evNzYuAAAApOjHpgYeDAZRlmUcHh5Gq9WKiIiyLKPT6cR4PI7d3d1bj1lVVQwGgxgOhzGfzyMioiiKGAwG0el0Ym9vL8bj8Sb/GAAAAPDkNXLmP8/zmM1ml8I/IiLLsjg4OIjhcHinM/WDwSBGo1H0+/3Vz9rtdhwfH0er1Yr9/f2YzWab+CMAAABAMhqJ/9FoFN1u91L41+pwH41GtxqzPljQ7Xa/WdZqtVYzCd69e3fLrQUAAIC0bTz+i6KIqqqi3W5fu0673Y7FYhFVVa097mKxiMViEb1e78rl9c+rqoqyLG+1zQAAAJCyjcf/hw8fIiLi5cuX166ztbUVEb8F/bpOTk5Wr7nqkoEsy1a/d/M/AAAA+JeNx38d9FdN+a/Vyz59+rT2uMPhMLIsi36/f+Wsgq9nEdz03gAAAPDcbPxu/3WE12f3r1Ivu820/3a7vTr7f5Wjo6PV73d2dtYeNyLi7OzsxuVfvny51XgAAADwmGw8/s/PzxtZ949MJpOIiNjd3b31mf/t7e2NbQcAAAA8No3c7f++zWazKIoisiyL8Xj80JsDAAAAj8rGz/zft6qq4t27d9FqtWI+n9/pev/T09Mbl3/58iV+/vnnO24hAAAAPKyNx//W1lZUVbXWlP6b7guwrsFgEBERx8fHl+74fxuvXr367u0AAACAx2rj0/7XOfNeHxj43rvy7+/vx9HR0XeFPwAAAKRu4/Ff32n/pjvzl2UZERFv3ry58/vkeR6TySQ+f/4s/AEAAOAGG4//Xq8XETc/xq9e1u/37/Qei8UiJpNJHB8ffzN7YDabxWKxuNO4AAAAkKKNx38d9NcFeFVVUZZltNvtO41fFEWMRqM4PDy88rKBT58+mQkAAAAAX2nkUX/j8TjKslxN7//ax48fIyLi4ODgm2VlWUan04nhcHjluPWd/evXVlW1+lWWZRRFEbPZTPwDAADAVxp51N/e3l58+vQper3epan59Vn78Xh85Zn/yWQSRVFEURQxHA4vrVNVVXQ6ndUBgusIfwAAALiskfiPiJhOp5HneQwGg8iyLM7Pz6OqqphOp9Htdq98zdu3b1dn7n9/cODXX3+9cibB74l/AAAAuOyH5XK5fOiNeOzOzs5ie3s7IiJOT0/j1atXD7xFAAAAPDaPuR0bueYfAAAAeDzEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACTuxyYHz/M8ptNpZFkW5+fnERHx/v37aLfbj3JcAAAASFFj8T8YDKIsyzg8PIxWqxUREWVZRqfTifF4HLu7u49qXAAAAEhVI/Gf53nMZrO4uLhYBXpERJZlcXBwEIPBIHZ2dm59pr6pcQEAACBlPyyXy+WmB33x4kXs7OzEfD6/+k1/+CG63e61y+973D9ydnYW29vbERFxenoar1692uj4AAAAPH2PuR03fsO/oiiiqqobz7632+1YLBZRVdWDjwsAAACp23j8f/jwISIiXr58ee06W1tbERGxWCwefFwAAABI3cbjvw7vr6/J/7162adPnx58XAAAAEjdxm/4V0+5r8/CX6Vedpvp+U2NG/HbdRk3OT09Xf3+y5cvtxobAACA5+HrXvznP//5gFvyrY3H//n5+ZNaNyJWN2RYx88//3yrsQEAAHh+/v73v8e///u/P/RmrGx82j8AAAA8d//7v//70JtwycbP/D9FX0/rv8rnz5/jv/7rvyIi4r//+79vNVMAHqsvX76sZrL87W9/i59++umBtwi+n/2aFNmvSZH9mlSdnp7GX//614iI+I//+I8H3prLNh7/W1tbUVXVWlPvb7p+/77GjYhbPXtxe3v7UT2rETbhp59+sl+THPs1KbJfkyL7Nan605/+9NCbcMnGp/3fdDf+Wh3w66zb9LgAAACQuo3H/87OTkREnJycXLtOWZYREfHmzZsHHxcAAABSt/H47/V6EXHz4/bqZf1+/8HHBQAAgNRtPP7r8F4sFlcur6oqyrKMdrv9KMYFAACA1DXyqL/xeBxlWa6m4X/t48ePERFxcHDwzbKyLKPT6cRwONzouAAAAPCcNRL/e3t70e/3o9frXZqmXxRFjEajGI/HV56hn0wmURRF5HkeRVFsbFwAAAB4zjb+qL/adDqNPM9jMBhElmVxfn4eVVXFdDqNbrd75Wvevn0bs9kssiy7NuLvMi4AAAA8Zz8sl8vlQ28EAAAA0JxGpv0DAAAAj4f4BwAAgMSJfwAAAEic+AcAAIDEiX8AAABInPgHAACAxIl/AAAASJz4BwAAgMSJfwAAAEjcjw+9Afctz/OYTqeRZVmcn59HRMT79++j3W4/ynFhHU3tf/v7+zGfz+Po6Ci2trai3W7br7k39/m52ul04uDgwL7NvWhy3y7LMsbj8epzOyJiMBjE7u7ud48NN2lqv57NZvHhw4eIiKiqKiIihsNh9Pv97xoX1lUURQwGgzg+Po5Wq/Xd4z1oNy6fkX6/v2y328uLi4vVz05OTpatVms5mUwe3biwjib2v4uLi2W3211Op9PVz46Pj5dZli0jYrm3t/e9mw03us/P1b29vWVELI+Pjzc6LlylyX17MpksW63Wpc/u5fK3fdz3EZrU5Hfs37++/o7S7/fvPC6s4/j4eLm7u7uMiGVEXNq/7+qhu/HZxP9kMrn2L206nd75i19T48I6mtr/ut3ucj6ff/Pzi4uLZavVWkbEN18uYVPu83P1+Ph49Y+6z2qa1uS+XY/9+8/u+Xy+bLVay3a7fadx4Y80tV+Px+PleDy+dnmWZQ5q0YjxeLxst9vL3d3d1WfoJuL/MXTjs4n/Vqu17Ha71y6PiBuX3/e4sI4m9r/j4+MbX1OfJW21WrcaF9Z1n5+r3W532W63xT/3oql9++TkZBkRV54JHY/Hy4hYZll263FhHU3t11mWLU9OTq5dPh6PfcfmXmwq/h9DNz6LG/4VRRFVVd14HUW73Y7FYrG6lughx4V1NLX/LRaLWCwW0ev1rlxe/7yqqijL8lbbDH/kPj9XR6NRjEaj1XXR0KQm9+3hcBgRv10z+nt7e3sxmUxiPp/fakxYR5P7dVmWURTFtctbrdbqeml47B5LNz6L+K9vEvLy5ctr16m//C0WiwcfF9bR1P53cnKyes1V/+hmWbb6/U3/KMNd3NfnalmWUVVVdLvdO48Bt9HUvl2W5Wr9675U7u7uXvrshk1p+jP73bt3137XmM/nPsN5Mh5LNz6L+K//A950d8Z62adPnx58XFhHU/vfcDiMLMui3+9f+UXy66ORm7jjKXztvj5Xh8NhTCaTO78ebqupfXs2m0XEv8K/LMvVrBYnHmhak5/Z/X4/qqqKTqcTo9Hom/ddLBZXznaBx+ixdOOziP86Vm6a2lkvu800i6bGhXU0tf+12+04OTmJ6XR65fKjo6PV73d2dtYeF9ZxH5+r+/v733yRhKY1tW/XXxK3trZisVjEZDKJ4XAY79+/j6Io4sWLF2Zp0ZgmP7MPDg5WMbS/vx+vX7+OxWIReZ7HaDSKz58/OwnBk/FYuvHHxkZ+RG5zPdBjWBfW8VD7X322dHd31z+6bFzT+3VZlnFychJ7e3u3fi18j6b27a/vvTKfz2M8Hq/+997eXvzjH/+ITqcTx8fH9/MMaZ6VJj+zW61WfP78OQaDQSwWiyjLMnq9XmRZtrHnrcN9eSzd+CzO/AObMZvNoiiKyLLs0hdMeCqGw6F9l6TUZ4gWi8Xqxn9fq3/27t27+9ws2IhWqxW9Xu/SgauyLOMvf/mLy1rgDsQ/sJaqquLdu3fRarViPp874s6TU0/3t++Sknp/zrLsypv61T8risL0f56U+nr/iIjj4+O4uLiIfr+/Wtbr9Vb3vADW8yziv75+Yp0pFLd55FNT48I67nv/GwwGEfHbP8DuGk1Tmtqv6+n+7gzNQ2n6u8hNn8v1AYKv79kCm9Dkd5Fffvklut3u6jKtVqsV0+n00gkIM1p4Kh5LNz6L+F/nLE/9F3GbM0JNjQvruM/9b39/P46OjoQ/jWtqvzbdn4fW1L69zmdy/UXy+Ph47XFhHU3t13meR1mWV35ud7vd+Pz5c7Tb7aiqKvI8X3tceCiPpRufRfzXdySvn19+lfqGOW/evHnwcWEd97X/5Xkek8kkPn/+LPxpXBP7dVEUcXR0FJ1OJ16/fv3Nr/q60V9++WX1M9i0pj6z62nRN6m/UNq32bSm9uv5fH7jTK1WqxWHh4cR4aAWT8Nj6cZnEf+9Xi8ibn5sQr2svpboIceFddzH/lc/Nuqqu+rOZjM322Hjmtiv2+12XFxcxMnJyZW/6n378PBw9TPYtKY+s+tAWmdKv7v9s2lN7ddlWf7h1OdWqxVZljmoxZPwWLrxWcR//R/wulCpqirKsrz1P4pNjQvraHr/K4oiRqNRHB4eXjn96NOnT2YCsHE+V0lVU/t2lmWr6c9XfaksyzKqqopWq+WeF2xcU/t1t9td6wRDWZb2a56Ex/L95lnEf0TEeDyOsiwvPQ+39vHjx4iIODg4+GZZWZbR6XSufHzO94wLm9DUfl3f2b9+bf2lsv5gKooiZrOZ+KcRTe3Xf6TJ5+pCRLPfRb4e42v13dB9F6EpTezXw+EwyrK88Xr+PM+j3+87GMyj8SS6cfmM9Pv9ZZZly4uLi9XPjo+Pl61Wazkej698zd7e3jIilhGxPD4+3ti4sCmb3q8vLi6WWZatll/3K8uyJv9YPHNNfV7/3sXFxeo1k8lkE5sON2pq3x6Px8uIWM7n89XP5vP5MiKWe3t7G/0zwO81sV/P5/MrX39xcbHc29tbdrvdjf4Z4ConJyer/fTrz9erPIVu/GG5XC6bPbzwuOR5HtPpNLIsi/Pz86iqKkaj0bVThoqiiMFgEFmWxXw+39i4sEmb3K9Ho1Hs7+//4Xt2u90b/z8B36upz+uI355gMZlMLp3tr6oqsiyLVqvlBlI0qql9e7FYxHg8Xu3XWZbFcDj0XYR70cR+XVVV/Prrr6up0vV9AIbDoftp0ZjZbBa//vprVFX1zazAra2taLVa8fbt29VjKGtPoRufXfwDAADAc/NsrvkHAACA50r8AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4sQ/AAAAJE78AwAAQOLEPwAAACRO/AMAAEDixD8AAAAkTvwDAABA4v4/5yd46JL0ggQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for choose_id in [1,2,3]:\n",
    "model_U = FCNN(input_dim=dim,output_dim=1,num_hidden=3,hidden_dim=10,act=tanh)#.cuda()\n",
    "model   = Model(dim,model_U=model_U)#.cuda();\n",
    "SOL     = Solver(model)\n",
    "\n",
    "# print(model.mu,model.sigma,model.coef_U)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=torch.tensor(0.001).cuda())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=torch.tensor(0.001))\n",
    "scheduler = None\n",
    "_loss_step = SOL.train_model(data_train=X,data_test=X,\n",
    "                             get_loss=get_loss,optimizer=optimizer,scheduler=scheduler,\n",
    "                             n_steps=int(5e4+1),batch_size=500,n_show_loss=1000,use_tqdm=True)\n",
    "torch.cuda.empty_cache()\n",
    "plot_model(model)\n",
    "# torch.save(model.state_dict(), \"savee/model_\"+str(choose_id))\n",
    "#torch.save(model.state_dict(),\"savee/model_anaconda3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77f2b8b6-9f6d-4fae-ae29-87c4a6cb97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"savee/model_99\")\n",
    "#model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44b07f7a-fb98-4405-8790-18bc4afbc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax  = plt.subplots(1,1,figsize=(4,3),dpi=200,constrained_layout=True)\n",
    "# xx       = np.linspace(0,2,1000).reshape(-1,1)\n",
    "# U_NN     = model.get_U_np(xx)\n",
    "# U_NN_min = U_NN.min()\n",
    "# U_NN     = U_NN-U_NN_min\n",
    "# c        = ax.plot(xx[:,0],U_NN,'-',lw=1.5)\n",
    "# ax.legend(fontsize=10)\n",
    "# ax.set_xlabel('$x$',fontsize=10)\n",
    "# ax.set_ylabel('$U(x)$',fontsize=10)\n",
    "# ax.set_xlim([0,2])\n",
    "# ax.set_yticks([0,0.2,0.4,0.6,0.8,1,1.2])\n",
    "# ax.set_xticks([0,.5,1.,1.5,2])\n",
    "# ax.yaxis.grid(linestyle='--')\n",
    "# ax.tick_params(axis=\"both\", labelsize=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc4b4d82-80a8-422e-a7d9-d2623106808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839674fe",
   "metadata": {},
   "source": [
    "# Visualizing the results for different a_k(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "344c6cc7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_models(models):\n",
    "    \n",
    "    xx       = np.linspace(0,2,1000).reshape(-1,1)\n",
    "    fig, ax  = plt.subplots(1,1,figsize=(4,3),dpi=200,constrained_layout=True)\n",
    "    \n",
    "    for k,model_name in enumerate(models):\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "        U_NN     = model.get_U_np(xx)\n",
    "        U_NN_min = U_NN.min()\n",
    "        U_NN     = U_NN-U_NN_min\n",
    "        c        = ax.plot(xx[:,0],U_NN,'-',lw=1.5,label=\"$a_{%d}(x)$\"%(k+1))\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.set_xlabel('$x$',fontsize=10)\n",
    "    ax.set_ylabel('$U(x)$',fontsize=10)\n",
    "    ax.set_xlim([0,2])\n",
    "    ax.set_yticks([0,0.2,0.4,0.6,0.8,1,1.2])\n",
    "    ax.set_xticks([0,.5,1.,1.5,2])\n",
    "    ax.yaxis.grid(linestyle='--')\n",
    "    ax.tick_params(axis=\"both\", labelsize=10)\n",
    "    plt.show()\n",
    "    \n",
    "# plot_models([\"savee/model_anaconda3\"])\n",
    "#plot_models([\"savee/model_a1_update\", \"savee/model_a2_update\", \"savee/model_a3_update\", \"savee/model_a4\", \"savee/model_a5_update\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0851750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b79c6ed-2669-4f78-a26d-a70b834146d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load(\"/Users/annacoletti/Desktop/savee/model_a3_update.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "319e3d20-3380-447c-9b87-866c7b207395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io as scio\n",
    "# from scipy.io import savemat\n",
    "# scio.savemat('W2_learned_DL', U_NN)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
